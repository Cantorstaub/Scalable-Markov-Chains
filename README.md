# Scalable Markov Chains

- _Python 3_
- commentary in German

For instructions on how to use the program, go to the `Instructions.md` file.

The program _Scalable Markov Chains_ was created while teaching the seminar _Programming in Python as AI Critique_ at the University of Regensburg in 2025. It analyzes arbitrary input text and stores the probabilities for symbols to follow each other. The program then creates new text randomly by using these probabilities.

For example, the program goes through the input text and collects all symbols following the letter `e`. It then does this for every letter or symbol in the input text, until it has information about any instance of a symbol following another in the text. This information then represents the probability of any specific symbol to follow another one. There might have been many instances of the letter `n` following the letter `e`. Therefore, when the program later on creates new output text and it has to decide which letter should follow an `e`, it would choose the letter `n` with high probability. In this way, the program creates output text with _transition probabilities_ between symbols similar to those in the input text. In this way, one could say, the program _mimics_ or _imitates_ the input text by creating new output text with similar chances of specific symbols following one another. This simple method of analyzing and then using the probabilities within the input text enables the program to create language-like output text. For a deeper understanding of the subject matter, see the `Instructions.md` file and the commentary in the program in the `SMC_Program.py` file (the latter one in German).

The main feature of the program is that it is _scalable_. In this context, being scalable means that the program is not bound to look only at a single letter like `e`, when it collects all symbols following another. It is able to look at more symbols and to check which symbols follow in such groups of symbols. So, instead of looking only at single letters like `e`, the program can be tasked to also look at digrams, that is, pairs of two symbols like `er`, and collect all symbols following such digrams. Similarly, you can increase the length of these groups of symbols from digrams to trigrams, looking at groups of three symbols like `ert`, and so forth, and thus scale the program up ad libidum – with the increasing running time and the storage of your hard drive being the only restrictions – to see how the quality of the output texts changes when scaling up.

To embed your hands-on engagement with the program within discursive analysis from the perspective of Media Studies, the texts of Claude E. Shannon [[1]](#_ftn1) and Friedrich A. Kittler [[2]](#_ftn2) would be a suitable starting point. Indeed, this program was developed in reference to these works to study the output of simple discrete-time Markov chains for different lengths of groups of symbols. I was interested in the question of how the quality of the output text would change in response to different input texts and to changes in the length of the n-grams of symbols. Beyond that, this program creates a media archaeological tool to think about the functionalities and limitations of contemporary forms of LLMs and the creation of text by computational means in general.

Programmer’s note: As the program is intended for didactic purposes and newcomers to _Python_, the program is easily accessible and understandable. For instance, the program does not use numerical values to store the probabilities of symbols following each other. Instead, all combinations of symbols up to the chosen length are stored in a dictionary and together represent these probabilities without the need to add another level of abstraction to the program’s structure.

## References

[[1]](#_ftnref1) You can compare the output of your program with the historical one from Shannon in: Shannon, Claude E. (1948): A Mathematical Theory of Communication. In: _Bell System Technical Journal_ 27/3, pp. 379–423, here: p. 388. This is only the first part of this paper. The second part was published in the October issue of the same journal on pages 623–656. If you prefer a translated German version of Shannon’s paper, see: Shannon, Claude E. (2000): _Ein/Aus. Ausgewählte Schriften zur Kommunikation- und Nachrichtentheorie_. Edited by Kittler, Friedrich A./Berz, Peter/Hauptmann, David/Roch, Axel. Berlin: Brinkmann und Bose, p. 20.

[[2]](#_ftnref2) Kittler, Friedrich A. (1997): The World of the Symbolic – A World of the Machine. In: Kittler, Friedrich A.: _Literature, Media, Information Systems. Friedrich A. Kittler Essays_. Edited by John Johnston. Critical Voices in Art, Theory and Culture. The series is edited by Saul Ostrow. Translated by Stefanie Harris. London/New York: Routledge, pp. 130–146, the passage on Shannon’s Markov chains is on pp. 140–141. The German version was published in: Kittler, Friedrich A. (1993): ‚Die Welt des Symbolischen - eine Welt der Maschine‘. In: _Draculas Vermächtnis. Technische Schriften_. 1st edition. Leipzig: Reclam, pp. 58–80, where you find the passage on Shannon’s Markov chains on p. 73.
